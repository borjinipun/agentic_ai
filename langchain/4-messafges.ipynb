{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99969eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd5349",
   "metadata": {},
   "source": [
    "Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9013eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user wants to know what artificial intelligence is. Let me start by recalling the basic definition. AI is the simulation of human intelligence in machines. But I should explain it more clearly. Maybe break it down into parts.\\n\\nFirst, mention that AI is a field within computer science. Then talk about tasks like learning, reasoning, problem-solving, perception, and language understanding. Give examples like chatbots or recommendation systems to make it relatable.\\n\\nI should differentiate between narrow AI and general AI. Most current applications are narrow, designed for specific tasks. General AI is still theoretical. Maybe mention common techniques like machine learning and deep learning.\\n\\nApplications are important too. Areas like healthcare, finance, self-driving cars. Also, address common misconceptions, like AI not being sentient. Emphasize that it\\'s a tool developed by humans.\\n\\nNeed to structure it logically: definition, types (narrow vs. general), techniques, applications, challenges. Keep it simple and avoid jargon. Check if I\\'m missing any key points. Maybe mention ethics and societal impact briefly. Alright, that should cover it without being too technical.\\n</think>\\n\\nArtificial Intelligence (AI) is a branch of computer science focused on creating systems or machines that can perform tasks requiring human-like intelligence. These tasks include **learning, reasoning, problem-solving, perception, language understanding, and decision-making**. AI systems are designed to simulate cognitive functions and adapt to new information, often improving their performance over time.\\n\\n### Key Concepts:\\n1. **Types of AI**:\\n   - **Narrow AI (Weak AI)**: Designed for specific tasks (e.g., voice assistants like Siri, recommendation systems on Netflix, or image recognition tools). Most current AI applications fall into this category.\\n   - **General AI (Strong AI)**: A theoretical form of AI that can perform any intellectual task a human can do. This remains a goal for future research.\\n\\n2. **Core Techniques**:\\n   - **Machine Learning (ML)**: Algorithms that learn patterns from data (e.g., predicting outcomes based on historical data).\\n   - **Deep Learning**: A subset of ML using neural networks with multiple layers to model complex patterns (e.g., facial recognition, language translation).\\n   - **Natural Language Processing (NLP)**: Enabling machines to understand and generate human language (e.g., chatbots, translation tools).\\n   - **Computer Vision**: Teaching machines to interpret and analyze visual information (e.g., self-driving cars detecting pedestrians).\\n\\n3. **Applications**:\\n   - **Healthcare**: Diagnosing diseases, drug discovery, and personalized treatment.\\n   - **Finance**: Fraud detection, algorithmic trading, and risk management.\\n   - **Transportation**: Autonomous vehicles and route optimization.\\n   - **Retail**: Personalized shopping experiences and demand forecasting.\\n   - **Customer Service**: Chatbots and virtual assistants.\\n\\n4. **Challenges and Ethical Considerations**:\\n   - **Bias and Fairness**: AI systems can inherit biases from training data.\\n   - **Transparency**: Many AI models (e.g., deep learning) operate as \"black boxes,\" making their decisions hard to interpret.\\n   - **Privacy**: Use of personal data for training raises concerns.\\n   - **Job Displacement**: Automation may impact employment in certain sectors.\\n   - **Security**: Risks of misuse, such as deepfakes or autonomous weapons.\\n\\n### Important Clarifications:\\n- AI is **not sentient**—it lacks consciousness, emotions, or self-awareness.\\n- AI systems are **tools** developed by humans, shaped by the data and goals they\\'re trained on.\\n- The term \"AI\" is often used broadly, but specific technologies like **machine learning**, **robotics**, or **expert systems** fall under its umbrella.\\n\\nIn summary, AI is a powerful and evolving field that enhances human capabilities in many domains, but its development and deployment require careful consideration of ethical, social, and technical challenges.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 803, 'prompt_tokens': 14, 'total_tokens': 817, 'completion_time': 1.551127855, 'completion_tokens_details': None, 'prompt_time': 0.002571378, 'prompt_tokens_details': None, 'queue_time': 0.057271712, 'total_time': 1.5536992330000001}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b537a-9759-7a40-9221-dfeb01e97c6a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 803, 'total_tokens': 817})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Please tell what is artificial intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08513a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, I need to explain what LangChain is. Let me start by recalling what I know about it. LangChain is a framework for building applications with large language models (LLMs). It helps connect LLMs with other tools and data sources. But I should be more specific.\\n\\nFirst, maybe break down the key components or features. LangChain probably has modules for different parts of the application lifecycle. Like data loading, prompt engineering, memory management, agents, and maybe a way to chain different components together. That makes sense because when you\\'re working with LLMs, you need to handle various inputs, process them, and maybe store some context.\\n\\nWait, I remember that LangChain has a concept called Chains. Chains are sequences of operations that can be executed in order. For example, you might have a chain that takes a user input, processes it with a prompt template, sends it to an LLM, and then uses the output in another step. That\\'s probably a core part of the framework.\\n\\nThen there are Agents. Agents are like more autonomous components that can decide which tools to use based on the input. They might use tools like databases, APIs, or other functions. So agents can perform more complex tasks by choosing the right action each time.\\n\\nMemory is another aspect. Since LLMs don\\'t have inherent memory, LangChain might provide ways to add short-term or long-term memory to an application. For example, keeping track of the conversation history in a chatbot so it can reference previous messages.\\n\\nPrompt templates are probably used to standardize how inputs are formatted for the LLM. This helps in generating consistent and effective prompts, which can improve the model\\'s responses.\\n\\nData loading and processing modules might help in extracting information from various sources like PDFs, databases, or web pages. Then, they can use techniques like embeddings to make the data searchable or useful for the LLM.\\n\\nI should also mention the tools and integrations. LangChain likely supports integration with different LLMs like OpenAI, Hugging Face, etc., and other services like databases, APIs, and storage solutions. This makes it flexible for different use cases.\\n\\nUse cases could include chatbots, data analysis tools, automation scripts, or anything that requires interacting with an LLM and external systems. For example, a customer support chatbot that uses an LLM to generate responses and also queries a knowledge base for accurate information.\\n\\nI need to structure this in a logical way. Start with a definition, then break down the main components (Chains, Agents, Memory, Prompts, Data loading, etc.), followed by use cases and benefits. Maybe end with how it compares to other frameworks or why someone would choose LangChain.\\n\\nWait, I should check if I\\'m missing any key features. Oh, there\\'s also the concept of Callbacks, which might be for monitoring and logging the application\\'s behavior. And maybe Evaluation tools to assess the performance of the application.\\n\\nAlso, the ecosystem around LangChain—like community contributions, documentation, and examples—might be important to mention. It\\'s open-source, which allows for customization and extension.\\n\\nLet me make sure I\\'m not confusing LangChain with other similar frameworks like Hugging Face\\'s Transformers or Ray. LangChain is specifically about building applications around LLMs, connecting them with various components and tools.\\n\\nI should also mention that LangChain abstracts away some of the complexity in working with LLMs, making it easier for developers to create robust applications without deep expertise in machine learning.\\n\\nOkay, putting it all together in a coherent way. Start with a simple definition, then go into the core components, use cases, and benefits. Maybe include an example of how a chatbot would be built using LangChain\\'s components.\\n</think>\\n\\n**LangChain** is an open-source framework designed to simplify the development of applications powered by **Large Language Models (LLMs)**. It provides tools to integrate LLMs with external data sources, APIs, and tools, enabling the creation of sophisticated, context-aware applications. Here\\'s a structured breakdown:\\n\\n---\\n\\n### **Key Components of LangChain**\\n1. **Chains**  \\n   - **Definition**: Sequences of operations (e.g., LLM calls, data processing) executed in a specific order.  \\n   - **Example**: A chain might first use a **prompt template** to format user input, send it to an LLM, and then pass the result to a database query tool.  \\n   - **Use Case**: Automating workflows like answering questions based on a company\\'s internal documents.\\n\\n2. **Agents**  \\n   - **Definition**: Autonomous components that decide which tools or actions to use based on input.  \\n   - **Example**: An agent might choose to search the web, query a database, or call an API depending on the user\\'s query.  \\n   - **Use Case**: A customer support chatbot that dynamically selects the right tool (e.g., ticketing system, knowledge base) to resolve issues.\\n\\n3. **Memory**  \\n   - **Definition**: Mechanisms to retain context across interactions (short-term or long-term).  \\n   - **Example**: Storing conversation history in a chatbot to maintain context over multiple messages.  \\n   - **Use Case**: A personal assistant that remembers user preferences or past interactions.\\n\\n4. **Prompt Templates**  \\n   - **Definition**: Structured templates to generate consistent, optimized prompts for LLMs.  \\n   - **Example**: Formatting a user\\'s query into a standardized structure for better LLM responses.  \\n   - **Use Case**: Ensuring a legal Q&A app uses precise phrasing to extract accurate answers from contracts.\\n\\n5. **Data Loading & Processing**  \\n   - **Tools**: Load data from sources like PDFs, databases, or APIs, and convert it into LLM-friendly formats (e.g., embeddings).  \\n   - **Example**: Extracting text from research papers and using embeddings to build a searchable knowledge base.  \\n   - **Use Case**: A research assistant that answers questions by retrieving relevant academic articles.\\n\\n6. **Callbacks & Evaluation**  \\n   - **Callbacks**: Track application behavior (e.g., logging, monitoring) for debugging or analytics.  \\n   - **Evaluation**: Tools to assess application performance (e.g., accuracy, latency).  \\n   - **Use Case**: Measuring how well a chatbot answers FAQs compared to a human baseline.\\n\\n---\\n\\n### **Use Cases**\\n- **Chatbots/Assistants**: Context-aware conversational agents (e.g., customer support, personal finance advisors).  \\n- **Data Analysis**: Querying databases or generating reports using LLMs.  \\n- **Automation**: Integrating LLMs with tools like spreadsheets, email, or CRMs.  \\n- **RAG (Retrieval-Augmented Generation)**: Combining LLMs with external data sources for accurate, up-to-date answers.\\n\\n---\\n\\n### **Why Use LangChain?**\\n- **Simplicity**: Abstracts complexity in connecting LLMs with tools and data.  \\n- **Flexibility**: Supports multiple LLMs (OpenAI, Hugging Face, etc.) and integrates with APIs, databases, and more.  \\n- **Extensibility**: Open-source community-driven ecosystem with plugins for custom tools.  \\n- **Scalability**: Design patterns (e.g., chains, agents) enable modular, maintainable applications.\\n\\n---\\n\\n### **Example Workflow**\\n1. **User Input**: \"What was the sales revenue in Q1?\"  \\n2. **Prompt Template**: Formats the query for the LLM.  \\n3. **LLM**: Generates a plan to retrieve sales data.  \\n4. **Agent**: Executes the plan by querying a database.  \\n5. **Response**: Returns the revenue figure to the user.\\n\\n---\\n\\n### **Comparison to Other Frameworks**\\n- **Hugging Face Transformers**: Focuses on model training and inference.  \\n- **LangChain**: Specializes in **application development** around LLMs, emphasizing integration with tools and workflows.\\n\\nLangChain empowers developers to build robust, intelligent applications by bridging the gap between LLMs and real-world systems. Its modular design and rich ecosystem make it a go-to choice for advanced AI applications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1678, 'prompt_tokens': 12, 'total_tokens': 1690, 'completion_time': 3.692445782, 'completion_tokens_details': None, 'prompt_time': 0.000279015, 'prompt_tokens_details': None, 'queue_time': 0.158678934, 'total_time': 3.692724797}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b537b-807c-7cb1-916e-0cec7b09023c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 1678, 'total_tokens': 1690})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2f3a8",
   "metadata": {},
   "source": [
    "Message prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b36736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
